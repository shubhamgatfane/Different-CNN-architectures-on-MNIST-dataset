{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN on MNIST Task3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"HBGPHhnzE59n","colab_type":"code","outputId":"fb388b84-6a49-490d-a8f5-bd71b848eb67","colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"status":"ok","timestamp":1551934431437,"user_tz":-330,"elapsed":556013,"user":{"displayName":"Shoobham Gatfane","photoUrl":"","userId":"07090839641092520380"}}},"cell_type":"code","source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 12\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","# Initialising the CNN model\n","model = Sequential()\n","\n","# 1st Convolution Layer #Pooling\n","model.add(Conv2D(32, kernel_size=(7, 7), activation='relu', input_shape=input_shape,padding='same'))\n","model.add(BatchNormalization())\n","\n","\n","# Adding 2nd convolutional layer #Pooling\n","model.add(Conv2D(32, (7, 7), activation='relu',padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))     \n","\n","\n","# Adding 3rd convolutional layer\n","model.add(Conv2D(64, (7, 7), activation='relu',padding='same'))\n","model.add(BatchNormalization())\n","\n","\n","# Adding 4th convolutional layer\n","model.add(Conv2D(64, (7, 7), activation='relu',padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n","\n","# Adding 5th convolutional layer\n","model.add(Conv2D(128, (7, 7), activation='relu',padding='same'))\n","model.add(BatchNormalization())\n","\n","# Adding 6th convolutional layer\n","model.add(Conv2D(128, (7, 7), activation='relu',padding='same'))\n","model.add(BatchNormalization())\n","\n","# Adding 7th convolutional layer\n","model.add(Conv2D(256, (7, 7), activation='relu',padding='same'))\n","model.add(BatchNormalization())\n","\n","\n","#Pooling\n","model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))       \n","\n","#Dropout\n","model.add(Dropout(0.30))\n","\n","#Flatten Operation\n","model.add(Flatten())\n","\n","#Applying ANN\n","model.add(Dense(256, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/12\n","60000/60000 [==============================] - 51s 849us/step - loss: 0.1519 - acc: 0.9555 - val_loss: 0.0825 - val_acc: 0.9784\n","Epoch 2/12\n","60000/60000 [==============================] - 45s 743us/step - loss: 0.0466 - acc: 0.9860 - val_loss: 0.0267 - val_acc: 0.9914\n","Epoch 3/12\n","60000/60000 [==============================] - 45s 755us/step - loss: 0.0271 - acc: 0.9918 - val_loss: 0.0409 - val_acc: 0.9875\n","Epoch 4/12\n","60000/60000 [==============================] - 45s 753us/step - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0172 - val_acc: 0.9941\n","Epoch 5/12\n","60000/60000 [==============================] - 44s 734us/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0239 - val_acc: 0.9931\n","Epoch 6/12\n","60000/60000 [==============================] - 44s 732us/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0191 - val_acc: 0.9947\n","Epoch 7/12\n","60000/60000 [==============================] - 44s 728us/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0186 - val_acc: 0.9945\n","Epoch 8/12\n","60000/60000 [==============================] - 45s 748us/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.0244 - val_acc: 0.9943\n","Epoch 9/12\n","60000/60000 [==============================] - 46s 761us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0201 - val_acc: 0.9953\n","Epoch 10/12\n","60000/60000 [==============================] - 44s 740us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0177 - val_acc: 0.9957\n","Epoch 11/12\n","60000/60000 [==============================] - 45s 756us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0218 - val_acc: 0.9945\n","Epoch 12/12\n","60000/60000 [==============================] - 45s 758us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0202 - val_acc: 0.9956\n","Test loss: 0.020179684552995923\n","Test accuracy: 0.9956\n"],"name":"stdout"}]}]}